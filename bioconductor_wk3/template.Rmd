---
title: "Template code for single-cell analysis using Bioconductor"
author: "Kevin Rue-Albrecht"
date: "05/10/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library(   )
```

# Exercise

## Import scRNA-seq data and create a SingleCellExperiment object

- Import the filtered matrix into R; use `DropletUtils`.

**Note:** use the `samples=` argument of the `DropletUtils::read10xCounts()` function to give a memorable name to each sample.
  Check the difference without using the `samples` argument.

```{r}
library(DropletUtils)
sce <- DropletUtils::read10xCounts(samples = c("filtered" = "~/OBDS_training/bioconductor_wk3/data/"))
#sce_nosample <- DropletUtils::read10xCounts("~/OBDS_training/bioconductor_wk3/data/matrix.mtx.gz")

```

- Print the object.
  What can you tell about its contents?
  
```{r}
str(sce)
```

> Answer:
>
  
- What can you tell from the object metadata?

**Note:** slots of `SummarizedExperiment` objects are typically accessed using functions of the same name, e.g. `metadata()`.

```{r}
metadata(sce)
```

> Answer:
>

# Exercise

## Quality control

- Compute and visualise quality control metrics (library size, genes detected, mitochondrial fraction); use `scuttle` and/or `scater`.

  + Identify mitochondrial genes and pass those to the `subsets` argument of the `scuttle::addPerCellQC()` function.

  + What is the return value?
    Where are the quality metrics stored?
    What is the difference with `scuttle::perCellQCMetrics()`?

```{r}

is.mito <- grepl("^MT-", rowData(sce)$Symbol)
table(is.mito)
```

```{r}
library(scuttle)
library("tidyverse")
sce <- scuttle::addPerCellQC(sce, percent_top = 50, subset = list(MT=is.mito))
colnames(colData(sce))

```

> Answer:
>

- Visualise library size, genes detected and mitochondrial fraction as three violin plots; use `ggplot2`.

```{r}
plot1 <- colData(sce)%>%
    as_tibble()%>%  
    ggplot() +
    geom_violin(aes(Sample, sum )) +
    labs(x = "Total UMI", y = "Value")
plot2 <- colData(sce) %>%
    as_tibble() %>% 
    ggplot() +
    geom_violin(aes(Sample, detected)) +
    labs(x = "Genes detected", y = "Value")
plot3 <- colData(sce) %>%
    as_tibble() %>% 
    ggplot() +
    geom_violin(aes(Sample, subsets_MT_percent)) +
    labs(x = "Percentage mitochondrial", y = "Value")
cowplot::plot_grid(plot1, plot2, plot3, nrow = 1)
```

- Filter cells, keeping those with more than 4,500 UMI, less than 15% mitochondrial UMI, and more than 1,500 genes detected. 

```{r}
sce <- sce[ ,sce$sum > 4500 & sce$subsets_MT_percent < 15 & sce$detected > 1500 ]
sce

#subsetting based on features:
sce[,which(assay(sce)['ENSG00000075624',] > 50)] # this subsets based on ENSG00000075624 with and expression level greater than 50.
```

- Similarly, use `scuttle::perFeatureQCMetrics()` or `scuttle::addPerFeatureQC()` to compute per-feature quality metrics, and visualise those metrics.

```{r}
sce <- scuttle::addPerFeatureQC(sce )
sce
```

```{r}
## ggplot2

rowData(sce) %>%
    as_tibble() %>%
    ggplot() +
    geom_point(aes(detected / 100 * ncol(sce), log10(mean)))


```

# Exercise step 3. Normalisation

- Convert the counts into normalized expression values to eliminate cell-specific biases (e.g., in capture efficiency); use `scuttle` and/or `scran`.
  Display the names of the assays available after that step.

**Note:** use `scuttle::logNormCounts()` to compute log-normalised counts.
  What is the return value?
  Where can you find the normalised counts?

```{r}
library(scuttle)
sce <- scuttle::logNormCounts(sce)
assayNames(sce)
```

> Answer:
> 

- Plot the variance against the mean of each gene.

**Note:** how can you tell whether the normalisation was effective?
  Compare with https://osca.bioconductor.org/feature-selection.html#quantifying-per-gene-variation

```{r}
library(DelayedMatrixStats)
#
x <- DelayedArray(assay(sce, "counts"))
plot_data <- tibble(
    mean = DelayedMatrixStats::rowMeans2(x),
    variance = DelayedMatrixStats::rowVars(x)
)
plot_counts <- ggplot(plot_data, aes(mean, variance)   ) +
    geom_point()
#
x <- DelayedArray(assay(sce, "logcounts"))
plot_data <- tibble(
    mean = DelayedMatrixStats::rowMeans2(x),
    variance = DelayedMatrixStats::rowVars(x)
)
plot_logcounts <- ggplot(plot_data, aes(mean, variance)   ) +
    geom_point()
cowplot::plot_grid(plot_counts, plot_logcounts, nrow = 1)
```

> Answer:
> 

- When would you rather use `scuttle::computePooledFactors` instead?

> Answer:
> 
> 

# Exercise

## Feature selection

Select features for downstream analyses, e.g. highly variable genes; use `scran`.

- Use `scran::modelGeneVar()` to model the variance of the log-expression profiles for each gene.
  What is the output?

```{r}
library(scran)
dec <- scran::modelGeneVar(sce)
dec
```

> Answer:
> 

- Visualise the relation between the mean expression of each gene and the total / biological / technical variance of each gene.

How do you interpret those different values?

```{r}
ggplot(as_tibble(dec)) +
    geom_point(aes(mean, total), color = "black") +
    geom_point(aes(mean, bio), color = "blue") +
    geom_point(aes(mean, tech), color = "red")
```

> Answer:
> 

- Use `scran::getTopHVGs()` to identify highly variable genes (e.g., top 10%).

What is the output?
How many genes do you identify?
Where are those genes located in the mean vs. (biological) variance plot?
What happens to this plot if you set more stringent thresholds to define highly variable genes?

```{r}
hvg <- scran::getTopHVGs(dec, prop = 0.1)
length(hvg)
```


```{r}
## ggplot2
dec %>%
    as_tibble() %>%
    mutate(
        gene_id = rownames(dec),
        hvg = gene_id %in% hvg
    ) %>%
    ggplot() +
    geom_point(aes(mean, bio, color = hvg))




```

> Answer:
> 
> 

# Exercise

## Dimensionality reduction

- Apply PCA; use `scater` or `BiocSingular`.
  Set a seed to control reproducibility.
  List the names of dimensionality reduction results available.

**Note:** only give the set of highly variable genes to the `scater::runPCA()` function, to save time, memory, and to focus on biologically informative genes in the data set.

```{r}
set.seed(1234)
sce <- scater::runPCA(sce, subset_row = hvg )
reducedDimNames(sce)
```

- Apply UMAP and t-SNE successively on the output of the PCA.
  List the names of dimensionality reduction results available each time.

```{r}
sce <- scater::runUMAP(sce,  dimred="PCA", pca = 20, ncomponents = 2)
reducedDimNames(sce)
```

```{r}
sce <- scater::runTSNE(sce, dimred="PCA", pca =20)
reducedDimNames(sce)

```

- Visualise the scatterplot of cells produced by each of those dimensionality reduction methods.
  Considering coloring points with quality control metrics.
  
```{r}
sce_pca <- scater::plotReducedDim(sce, dimred = "PCA")
sce_pca
```
```{r}
sce_umap <- scater::plotReducedDim(sce, dimred = "UMAP")
sce_umap
```
```{r}
sce_tSNE <- scater::plotReducedDim(sce, dimred = "TSNE")
sce_tSNE
```
```{r}
cowplot::theme_cowplot(sce_pca, sce_umap, sce_tSNE)
scater::plotReducedDim(sce, dimred = "UMAP", colour_by = "subsets_MT_percent")
```
  
## Bonus point

- Use `scran::denoisePCA()` to remove principal components that correspond to technical noise, and compare downstream t-SNE or UMAP with those obtained before de-noising.
  Name the output `sce_denoise`.
  How many components remain after denoising?
  5
  Visualise a UMAP of the denoised PCA and compare.

```{r}
sce_denoise <- scran::denoisePCA(sce, dec, subset.row=hvg)
ncol(reducedDim(sce_denoise, "PCA"))

sce_denoise <- scater::runUMAP(sce_denoise, dimred = 'PCA')
reducedDimNames(sce_denoise)


```

```{r}
sce_denoise_umap <- scran::denoisePCA(sce, technical = dec, subset_row = hvg)
ncol(reducedDim(sce_denoise_umap, "UMAP"))
```

> Answer:
> 

```{r}
sce_denoise <- scater::runUMAP(   )

```

```{r}
#sce_denoise_umap <- 

library(cowplot)
p1 <- scater::plotReducedDim(sce, dimred = "UMAP", colour_by = "subsets_MT_percent")
p2 <- scater::plotReducedDim(sce_denoise, dimred = "UMAP", colour_by = "subsets_MT_percent")
plot_grid(p1, p2)


sce_denoise_umap <- reducedDim(x = sce_denoise, type = "UMAP") %>%
    as.data.frame() %>%
    as_tibble() %>%
    bind_cols(colData(sce_denoise) %>% as_tibble()) %>%
    ggplot() +
    geom_point(aes(V1, V2, color=subsets_MT_percent)) +
    cowplot::theme_cowplot()




plot_grid(
    sce_umap + theme(legend.position = "bottom"),
    sce_denoise_umap + theme(legend.position = "bottom"),
    nrow = 1)

```

# Exercise

## Clustering

Cluster cells using `scran`.

- Start with `scran::getClusteredPCs()` to cluster cells after using varying number of PCs, and pick the number of PCs using a heuristic based on the number of clusters.

```{r}
output <- scran::getClusteredPCs(reducedDim(sce, "PCA"))
metadata(output)$chosen
```

- Use `scran::buildSNNGraph()` and `igraph::cluster_louvain()` with that "ideal" number of PCs.
  Assign the cluster label to a cell metadata column named `"label"`.

```{r, message=FALSE}
g <- scran::buildSNNGraph(t(reducedDim(sce, "PCA")), d = metadata(output)$chosen)



g2 <- scran::buildSNNGraph(sce, use.dimred="PCA")
colData(sce)[["label"]] <- factor(igraph::cluster_louvain(g)$membership)

```

- Visualise the assigned cluster on your preferred dimensionality reduction layout.

**Note:** Dimensionality reduction and clustering are two separate methods both based on the PCA coordinates.
  They may not always agree with each other, often helping to diagnose over- or under-clustering, as well as parameterisation of dimensionality reduction methods.

```{r}
gg_snn <- reducedDim(x = sce, type = "UMAP") %>%
    as.data.frame() %>%
    as_tibble() %>%
    bind_cols(colData(sce) %>% as_tibble()) %>%
    sample_frac() %>%
    ggplot() +
    geom_point(aes(V1, V2, color=label)) +
    cowplot::theme_cowplot()
gg_snn
scater::plotReducedDim(sce, dimred = )
```

## Bonus point

- Test different numbers of principal components and compare results.

```{r, message=FALSE}
snn_plots <- list()
for (d in c(5, 10, 13, 15)) {
    g <- scran::buildSNNGraph(t(reducedDim(sce, "PCA")), d = d)
    colData(sce)[[sprintf("snn_d", d)]] <- factor(igraph::cluster_louvain(g)$membership)
    gg_d <- reducedDim(x = sce, type = "UMAP") %>%
        as.data.frame() %>%
        as_tibble() %>%
        bind_cols(colData(sce) %>% as_tibble()) %>%
        sample_frac() %>%
        ggplot() +
        geom_point(aes(V1, V2, color=snn_d)) +
        labs(title = d) +
        cowplot::theme_cowplot()
    snn_plots[[as.character(d)]] <- gg_d
}
plot_grid(plotlist = snn_plots, ncol = 2)
```

- Try `scran::quickCluster()`; identify key parameters and compare results.

```{r}
sce$quickCluster <- scran::quickCluster(sce )

gg_cluster <- reducedDim(x = sce, type = "UMAP") %>%
    as.data.frame() %>%
    as_tibble() %>%
    bind_cols(colData(sce) %>% as_tibble()) %>%
    sample_frac() %>%
    ggplot() +
    geom_point(aes(V1, V2, color=quickCluster)) +
    cowplot::theme_cowplot()
gg_cluster
```

# Exercise

## Cluster markers

- Use `scran::findMarkers()` to identify markers for each cluster.
  Display the metadata of markers for the first cluster.

```{r}
markers <- scran::findMarkers(sce, sce$label)
head(markers)
rowData(sce)[rownames(markers[[1]]), ] %>% 
    as.data.frame() %>% 
    head()

```

- Visualise the expression of selected markers:

  + As a dot plot, optionally with a violin layer.

```{r}
marker_id <- rownames(markers$`1`)[1]
marker_id <- "ENSG00000196154"
marker_name <- rowData(sce)[marker_id, "Symbol"]
colData(sce) %>%
    as_tibble() %>%
    mutate(marker = assay(sce, "logcounts")[marker_id, ]) %>%
    ggplot(aes(label, marker)) +
    geom_violin(aes(fill = label)) +
    geom_point() +
    labs(title = marker_id, subtitle = marker_name) +
    scale_color_viridis_c() + theme_bw()







```

  + On a dimensionality reduction layout.
    Compare with the cluster labels.

```{r}

gg_marker <- reducedDim(x = sce, type = "UMAP") %>%
    as.data.frame() %>%
    as_tibble() %>%
    mutate(marker = assay(sce, "logcounts")[marker_id, ]) %>%
    ggplot() +
    geom_point(aes(V1, V2, color=marker)) +
    scale_color_viridis_c() +
    labs(title = marker_id, subtitle = marker_name) +
    cowplot::theme_cowplot()
plot_grid(gg_marker, gg_snn)


```

# Exercise

## Interactive visualisation

- Use `iSEE::iSEE()` to launch an interactive web-application to visualise the contents of the `SingleCellExperiment` object.

```{r}
library(iSEE)
app <- iSEE(sce)
if (interactive()) {
  shiny::runApp(app)
}
```

## Bonus point

- Preconfigure the application to start with a subset of panels, e.g.

```{r}
initial_panel_list <- list(
  ReducedDimensionPlot(PanelWidth=4L),
  RowDataTable(PanelWidth=8L)
)
app <- iSEE::iSEE(sce, initial = initial_panel_list)
if (interactive()) {
  shiny::runApp(app)
}
```
